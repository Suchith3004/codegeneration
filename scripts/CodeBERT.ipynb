{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c26f66-7227-45fa-96d8-f3e7e2d16b58",
   "metadata": {},
   "source": [
    "# Code Generation using CodeBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ed571-22d9-4268-8084-9ba1dd4dc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats \n",
    "from transformers import RobertaTokenizer,RobertaModel,pipeline,RobertaConfig, AdamW\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from sklearn import metrics, model_selection\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm import tqdm \n",
    "import gc\n",
    "from sklearn import metrics, model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8cae1a-01a9-45d8-84ba-f620bf413d4a",
   "metadata": {},
   "source": [
    "### Set the language for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa7d05-b466-4db4-beff-9263cc562be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"sql\"\n",
    "#language = \"py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ec1d7-978f-4f8f-9589-4dce184b5b0c",
   "metadata": {},
   "source": [
    "### Check if GPU is avaialble for faster training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e64a69-fc16-4d95-9ca0-fcef0f60706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd339e7e-9ff7-4079-a300-068e4b9b7204",
   "metadata": {},
   "source": [
    "### Standardize Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec48b11-4f43-4884-b2ce-8c565ffa0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"Container for a single training/test features for a example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_ids,\n",
    "                 input_mask,\n",
    "                 target_ids,\n",
    "                 target_mask\n",
    "\n",
    "    ):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.target_ids =target_ids\n",
    "        self.target_mask = target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a828a-12de-4d83-8859-fa7e47c81d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(js,tokenizer,block_size):\n",
    "    '''Format each example through tokenization, padding and attaching start and end tokens'''\n",
    "\n",
    "    # Standardize Features\n",
    "    code = js['Code']\n",
    "    code_tokens=tokenizer.tokenize(code)[:block_size-2]\n",
    "    target_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "    target_ids =  tokenizer.convert_tokens_to_ids(target_tokens)\n",
    "    target_mask = [1] *len(target_ids)\n",
    "    padding_length = block_size - len(target_ids)\n",
    "    target_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "    target_mask+=[0]*padding_length   \n",
    "\n",
    "    # Standardize Target\n",
    "    nl = js['NL']\n",
    "    nl_tokens=tokenizer.tokenize(nl)[:block_size-2]\n",
    "    source_tokens =[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]\n",
    "    source_ids =  tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    padding_length = block_size - len(source_ids)\n",
    "    source_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "    source_mask = [1] * (len(source_tokens))\n",
    "    source_mask+=[0]*padding_length\n",
    "\n",
    "    return InputFeatures(source_ids,source_mask,target_ids,target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd445f-cba6-454d-aeef-078096ed4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(js,tokenizer,block_size):\n",
    "    #source\n",
    "    code = js['Code']\n",
    "    code_tokens=tokenizer.tokenize(code)[:block_size-2]\n",
    "    target_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "    target_ids =  tokenizer.convert_tokens_to_ids(target_tokens)\n",
    "    target_mask = [1] *len(target_ids)\n",
    "    padding_length = block_size - len(target_ids)\n",
    "    target_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "    target_mask+=[0]*padding_length   \n",
    "\n",
    "    nl = js['NL']\n",
    "    nl_tokens=tokenizer.tokenize(nl)[:block_size-2]\n",
    "    source_tokens =[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]\n",
    "    source_ids =  tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    padding_length = block_size - len(source_ids)\n",
    "    source_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "    source_mask = [1] * (len(source_tokens))\n",
    "    source_mask+=[0]*padding_length\n",
    "\n",
    "    return InputFeatures(source_ids,source_mask,target_ids,target_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a6f93-80d5-4e07-bcd8-5bbb4d5aac1a",
   "metadata": {},
   "source": [
    "### Build training and testing Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb71dd0-8d50-444d-868b-c049fdba30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeData(Dataset):\n",
    "    def __init__(self, tokenizer, dataset):\n",
    "        self.examples = []\n",
    "        for i in range(len(dataset)):\n",
    "          x = dataset.iloc[i]\n",
    "          self.examples.append(convert_examples_to_features(x,tokenizer,150))\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, indx):       \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21461c9-9a2b-4371-b106-5e4a82928812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "train_data = pd.read_csv(\"../StaQC_Data/{}_single_answer.train.csv\".format(language))\n",
    "val_data = pd.read_csv(\"../StaQC_Data/{}_single_answer.val.csv\".format(language))\n",
    "train_data = train_data[['NL', 'Code']]\n",
    "val_data = val_data[['NL', 'Code']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d83a10-6d73-4204-80c2-1fa819e31421",
   "metadata": {},
   "source": [
    "### Instantiate Microsoft's Pre-trained CodeBert Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a7b1b-957a-4d73-898c-b8f45a608808",
   "metadata": {},
   "outputs": [],
   "source": [
    "config= RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base',config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9247013-2977-4855-bd2e-1224c603e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(tokenizer= tokenizer, config=config,beam_size= 10,max_length=150,sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id).to(device)\n",
    "\n",
    "train_dataset = CodeData(tokenizer, train_data)\n",
    "val_dataset = CodeData(tokenizer,val_data)\n",
    "\n",
    "train_batch_size = 16\n",
    "torch.cuda.empty_cache()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size,shuffle=True,num_workers=1)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=train_batch_size,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd1953-7f31-4bc2-82a8-a259e5e184ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Beam(object):\n",
    "    def __init__(self, size,sos,eos):\n",
    "        self.size = size\n",
    "        self.tt = torch.cuda\n",
    "        # The score for each translation on the beam.\n",
    "        self.scores = self.tt.FloatTensor(size).zero_()\n",
    "        # The backpointers at each time-step.\n",
    "        self.prevKs = []\n",
    "        # The outputs at each time-step.\n",
    "        self.nextYs = [self.tt.LongTensor(size)\n",
    "                       .fill_(0)]\n",
    "        self.nextYs[0][0] = sos\n",
    "        # Has EOS topped the beam yet.\n",
    "        self._eos = eos\n",
    "        self.eosTop = False\n",
    "        # Time and k pair for finished.\n",
    "        self.finished = []\n",
    "\n",
    "    def getCurrentState(self):\n",
    "        \"Get the outputs for the current timestep.\"\n",
    "        batch = self.tt.LongTensor(self.nextYs[-1]).view(-1, 1)\n",
    "        return batch\n",
    "\n",
    "    def getCurrentOrigin(self):\n",
    "        \"Get the backpointers for the current timestep.\"\n",
    "        return self.prevKs[-1]\n",
    "\n",
    "    def advance(self, wordLk):\n",
    "        \"\"\"\n",
    "        Given prob over words for every last beam `wordLk` and attention\n",
    "        `attnOut`: Compute and update the beam search.\n",
    "        Parameters:\n",
    "        * `wordLk`- probs of advancing from the last step (K x words)\n",
    "        * `attnOut`- attention at the last step\n",
    "        Returns: True if beam search is complete.\n",
    "        \"\"\"\n",
    "        numWords = wordLk.size(1)\n",
    "\n",
    "        # Sum the previous scores.\n",
    "        if len(self.prevKs) > 0:\n",
    "            beamLk = wordLk + self.scores.unsqueeze(1).expand_as(wordLk)\n",
    "\n",
    "            # Don't let EOS have children.\n",
    "            for i in range(self.nextYs[-1].size(0)):\n",
    "                if self.nextYs[-1][i] == self._eos:\n",
    "                    beamLk[i] = -1e20\n",
    "        else:\n",
    "            beamLk = wordLk[0]\n",
    "        flatBeamLk = beamLk.view(-1)\n",
    "        bestScores, bestScoresId = flatBeamLk.topk(self.size, 0, True, True)\n",
    "\n",
    "        self.scores = bestScores\n",
    "\n",
    "        # bestScoresId is flattened beam x word array, so calculate which\n",
    "        # word and beam each score came from\n",
    "        prevK = bestScoresId // numWords\n",
    "        self.prevKs.append(prevK)\n",
    "        self.nextYs.append((bestScoresId - prevK * numWords))\n",
    "\n",
    "\n",
    "        for i in range(self.nextYs[-1].size(0)):\n",
    "            if self.nextYs[-1][i] == self._eos:\n",
    "                s = self.scores[i]\n",
    "                self.finished.append((s, len(self.nextYs) - 1, i))\n",
    "\n",
    "        # End condition is when top-of-beam is EOS and no global score.\n",
    "        if self.nextYs[-1][0] == self._eos:\n",
    "            self.eosTop = True\n",
    "\n",
    "    def done(self):\n",
    "        return self.eosTop and len(self.finished) >=self.size\n",
    "\n",
    "    def getFinal(self):\n",
    "        if len(self.finished) == 0:\n",
    "            self.finished.append((self.scores[0], len(self.nextYs) - 1, 0))\n",
    "        self.finished.sort(key=lambda a: -a[0])\n",
    "        if len(self.finished) != self.size:\n",
    "            unfinished=[]\n",
    "            for i in range(self.nextYs[-1].size(0)):\n",
    "                if self.nextYs[-1][i] != self._eos:\n",
    "                    s = self.scores[i]\n",
    "                    unfinished.append((s, len(self.nextYs) - 1, i)) \n",
    "            unfinished.sort(key=lambda a: -a[0])\n",
    "            self.finished+=unfinished[:self.size-len(self.finished)]\n",
    "        return self.finished[:self.size]\n",
    "\n",
    "    def getHyp(self, beam_res):\n",
    "        \"\"\"\n",
    "        Walk back to construct the full hypothesis.\n",
    "        \"\"\"\n",
    "        hyps=[]\n",
    "        for _,timestep, k in beam_res:\n",
    "            hyp = []\n",
    "            for j in range(len(self.prevKs[:timestep]) - 1, -1, -1):\n",
    "                hyp.append(self.nextYs[j+1][k])\n",
    "                k = self.prevKs[j][k]\n",
    "            hyps.append(hyp[::-1])\n",
    "        return hyps\n",
    "    \n",
    "    def buildTargetTokens(self, preds):\n",
    "        sentence=[]\n",
    "        for pred in preds:\n",
    "            tokens = []\n",
    "            for tok in pred:\n",
    "                if tok==self._eos:\n",
    "                    break\n",
    "                tokens.append(tok)\n",
    "            sentence.append(tokens)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577b88e2-bb03-466e-8943-73cff21f3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):   \n",
    "    def __init__(self, config,tokenizer,beam_size, max_length,sos_id,eos_id):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.config=config\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(2048, 2048)))\n",
    "        self.tokenizer=tokenizer\n",
    "        self.encoder = RobertaModel.from_pretrained('microsoft/codebert-base',config=config)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=6)\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.beam_size = beam_size\n",
    "        self.max_length = max_length\n",
    "        self.sos_id = sos_id\n",
    "        self.eos_id = eos_id\n",
    "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "        self.lsm = nn.LogSoftmax(dim=-1)\n",
    "        self.tie_weights()\n",
    "\n",
    "    def _tie_or_clone_weights(self, first_module, second_module):\n",
    "        \"\"\" Tie or clone module weights depending of weither we are using TorchScript or not\n",
    "        \"\"\"\n",
    "        if self.config.torchscript:\n",
    "            first_module.weight = nn.Parameter(second_module.weight.clone())\n",
    "        else:\n",
    "            first_module.weight = second_module.weight\n",
    "                  \n",
    "    def tie_weights(self):\n",
    "        \"\"\" Make sure we are sharing the input and output embeddings.\n",
    "            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n",
    "        \"\"\"\n",
    "        self._tie_or_clone_weights(self.lm_head,\n",
    "                                   self.encoder.embeddings.word_embeddings)    \n",
    "        \n",
    "    def forward(self,source_ids,source_mask,target_ids=None,target_mask=None): \n",
    "        \n",
    "        outputs = self.encoder(source_ids, attention_mask=source_mask)\n",
    "        encoder_output = outputs[0].permute([1,0,2]).contiguous()\n",
    "\n",
    "        attn_mask=-1e4 *(1-self.bias[:target_ids.shape[1],:target_ids.shape[1]])\n",
    "        tgt_embeddings = self.encoder.embeddings(target_ids).permute([1,0,2]).contiguous()\n",
    "        out = self.decoder(tgt_embeddings,encoder_output,tgt_mask=attn_mask,memory_key_padding_mask=(1-source_mask).bool())\n",
    "        hidden_states = torch.tanh(self.dense(out)).permute([1,0,2]).contiguous()\n",
    "        lm_logits = self.lm_head(hidden_states)\n",
    "            # Shift so that tokens < n predict n\n",
    "        active_loss = target_mask[..., 1:].ne(0).view(-1) == 1\n",
    "        shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "        shift_labels = target_ids[..., 1:].contiguous()\n",
    "        #print(active_loss,shift_logits.shape,shift_labels.shape)\n",
    "            # Flatten the tokens\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1))[active_loss],shift_labels.view(-1)[active_loss])\n",
    "\n",
    "        outputs = loss,loss*active_loss.sum(),active_loss.sum()\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6c1c1-b9fe-47ec-873d-8a92a8437c52",
   "metadata": {},
   "source": [
    "### Train and Validate the CodeBert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc044f-3492-4870-91f0-ae4caef347d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs= 8\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters()],\n",
    "         }]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr= 0.0001)\n",
    "    \n",
    "train_loss_graph = []\n",
    "val_loss_graph = []\n",
    "for idx in range(num_train_epochs): \n",
    "\n",
    "    tr_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        source_ids = batch[0].to(device) \n",
    "        source_mask = batch[1].to(device)\n",
    "        target_ids = batch[2].to(device)\n",
    "        target_mask = batch[3].to(device)#target_ids.ne(tokenizer.pad_token_id)\n",
    "        labels=batch[1].to(device)\n",
    "        model.train()\n",
    "        loss,_,_ = model(source_ids=source_ids,source_mask=source_mask.float(),target_ids=target_ids,target_mask=target_mask.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        source_ids = batch[0].to(device) \n",
    "        source_mask = batch[1].to(device)\n",
    "        target_ids = batch[2].to(device)\n",
    "        target_mask = batch[3].to(device)\n",
    "        labels=batch[1].to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            v_loss,_,_ = model(source_ids=source_ids,source_mask=source_mask,target_ids=target_ids,target_mask=target_mask)\n",
    "            val_loss +=v_loss.item()\n",
    "                \n",
    "    epoch_loss = tr_loss/len(train_dataloader)\n",
    "    epoch_val_loss = val_loss/len(val_dataloader)\n",
    "    print(\"epoch {} train loss {} val loss {}\".format(idx+1,epoch_loss,epoch_val_loss))\n",
    "    train_loss_graph.append(epoch_loss)\n",
    "    val_loss_graph.append(epoch_val_loss)\n",
    "    torch.save(model.state_dict(), 'CodeBERTmodel-SQL-{}.pkl'.format(idx+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b826c0-d158-43cf-8b83-52120e253386",
   "metadata": {},
   "source": [
    "### Plot Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea9efb-d1a0-4667-b08a-4f43d4a693a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch\")\n",
    "plt.plot(train_loss_graph,'k')\n",
    "plt.plot(val_loss_graph,'y')\n",
    "plt.legend([\"Training Loss\",\"Validation Loss\"])\n",
    "plt.savefig('Plot-Loss-SQL-CodeBERT.png')\n",
    "\n",
    "d = pd.DataFrame({'train_loss':train_loss_graph,'val_loss':val_loss_graph})\n",
    "d.to_csv('Losses_for_SQL_CodeBERT.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
