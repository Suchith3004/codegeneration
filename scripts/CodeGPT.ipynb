{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eeef68f-69ae-4540-a344-e1a090642906",
   "metadata": {},
   "source": [
    "# Code Generation using CodeGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38df1d-01cb-4cc8-a621-b3d615b2117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from transformers import RobertaTokenizer, AutoModelForCausalLM,GPT2Tokenizer,GPT2LMHeadModel,GPT2Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa1d82-2949-413e-bc72-4c2a5f5224ee",
   "metadata": {},
   "source": [
    "### Set the language for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9a6ab-221a-477a-aabe-93a83ec66b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"sql\"\n",
    "#language = \"py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ae3b0-893f-4952-be60-5f7c1e884de4",
   "metadata": {},
   "source": [
    "### Check if GPU is avaialble for faster training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4321ba0-90ee-4c58-9718-c770bfc972e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f7505-506d-4c64-82e0-29a14a5453b9",
   "metadata": {},
   "source": [
    "### Instantiate Microsoft's Pre-trained CodeGPT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863413c1-cc67-4682-8b2c-430ff704055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Pre-trained model\n",
    "CodeGPT = GPT2LMHeadModel.from_pretrained(\"microsoft/CodeGPT-small-java\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"microsoft/CodeGPT-small-java\",do_lower_case=True, bos_token='<s>', eos_token='</s>', pad_token='<pad>', unk_token='<|UNKNOWN|>', sep_token='concode_elem_sep')\n",
    "config = GPT2Config.from_pretrained(\"microsoft/CodeGPT-small-java\")\n",
    "\n",
    "# Adjust Tokenizer settings \n",
    "CodeGPT.resize_token_embeddings(len(tokenizer))\n",
    "CodeGPT.config.bos_token_id = tokenizer.bos_token_id\n",
    "CodeGPT.config.eos_token_id = tokenizer.eos_token_id\n",
    "CodeGPT.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Move model to GPU\n",
    "CodeGPT = CodeGPT.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216b792-cc42-4125-a3f6-425ff1e3a3da",
   "metadata": {},
   "source": [
    "### Build and Load the Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd411352-333c-4905-a9d3-7bab3e18da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training and Validation data\n",
    "data = pd.read_csv(\"../StaQC_Data/{}_single_answer.train.csv\".format(language))\n",
    "val_data = pd.read_csv(\"../StaQC_Data/{}_single_answer.val.csv\".format(language))\n",
    "data = train_data[[\"NL\",\"Code\"]]\n",
    "val_data = val_data[[\"NL\", \"Code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca2be6-30d9-4f9c-ae35-2d95a02490ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcodeDataset(Dataset):\n",
    "    '''Class to format the StaQC Single Answer Dataset'''\n",
    "    def __init__(self, tokenizer, data, file_type='train', block_size=150, mode='train'):\n",
    "\n",
    "            self.block_size = block_size\n",
    "            self.mode = mode\n",
    "            self.inputs = []\n",
    "            self.token_labels = []\n",
    "\n",
    "            datas = data\n",
    "\n",
    "            length = len(datas)\n",
    "\n",
    "            for idx in range(len(datas)):\n",
    "                x = datas.iloc[idx]\n",
    "                code = tokenizer.encode(x[\"Code\"])\n",
    "                nl = tokenizer.encode(x[\"NL\"])\n",
    "\n",
    "                input_ids, input_labels = self.pad_and_get_mask(code, nl, tokenizer)\n",
    "                self.inputs.append(input_ids)\n",
    "                self.token_labels.append(input_labels)\n",
    "\n",
    "\n",
    "    def pad_and_get_mask(self, code, nl, tokenizer):\n",
    "        '''Pad the extra space and mask the overflow'''\n",
    "        if self.mode == 'test':\n",
    "            code = []\n",
    "        while (len(code) + len(nl) + 2 > self.block_size):\n",
    "            if (len(code) > len(nl)):\n",
    "                code = code[:-1]\n",
    "            else:\n",
    "                nl = nl[:-1]\n",
    "        if self.mode == 'train':\n",
    "            inputs = nl + [tokenizer.bos_token_id] + code + [tokenizer.eos_token_id]\n",
    "            labels = [1] * len(nl) + [2] * (len(code)+1) + [0]\n",
    "        else:\n",
    "            inputs = nl + [tokenizer.bos_token_id]\n",
    "            labels = [1] * len(nl) + [2]\n",
    "            return inputs, labels\n",
    "        assert len(inputs) <= self.block_size\n",
    "        pad_len = self.block_size - len(inputs)\n",
    "        inputs += [tokenizer.pad_token_id] * pad_len\n",
    "        labels += [0] * pad_len\n",
    "        assert len(inputs) == len(labels)\n",
    "        return inputs, labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.inputs[item]), torch.tensor(self.token_labels[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d334c6-4de1-4abc-9848-75ae7b546ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Training and Testing dataset as Concode Variables\n",
    "dataset = ConcodeDataset(tokenizer, data, file_type='train',block_size=150)\n",
    "val_dataset = ConcodeDataset(tokenizer, val_data,mode='train', file_type='dev',block_size=150)\n",
    "\n",
    "# Create Dataloader for training and testing data to iterate through the batches\n",
    "train_dataloader = DataLoader(dataset, batch_size=16, drop_last=True,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, drop_last=True,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607210f-a6c8-4253-aba8-be4b01335642",
   "metadata": {},
   "source": [
    "### Train and Validate the CodeGPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47340ec6-c816-4b35-9293-7f0a261106ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Loss function and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(lr=0.00001,params = CodeGPT.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8bbfc-997c-429f-ba45-037b472468f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "num_epochs = 8\n",
    "\n",
    "train_loss_graph = []\n",
    "val_loss_graph = []\n",
    "\n",
    "# Loop through dataloader for each epoch\n",
    "for i in range(num_epochs):\n",
    "    tr_loss = 0.0\n",
    "    eval_loss = 0.0\n",
    "    \n",
    "    # Loop through all the batches for each epoch\n",
    "    for batch,token_labels in train_dataloader:\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Seperate and format both the features and targets\n",
    "        token_labels = token_labels.to(device)\n",
    "        attn_mask = torch.tensor(token_labels.clone().detach() != 0, dtype=torch.uint8)\n",
    "        loss_mask = torch.tensor(token_labels.clone().detach() == 2, dtype=torch.uint8)\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Train the GPT model on the current bath\n",
    "        CodeGPT.train()\n",
    "        \n",
    "        # Retrieve the new outputs after training\n",
    "        out = CodeGPT(batch,attention_mask=attn_mask)\n",
    "        \n",
    "        # Format output before calculating loss and gradients\n",
    "        logits = out.logits\n",
    "        labels = batch\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        flatten_shift_loss_mask = loss_mask[..., :-1].contiguous().view(-1)\n",
    "        ids = torch.nonzero(flatten_shift_loss_mask).view(-1)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = criterion(shift_logits.view(-1, shift_logits.size(-1))[ids], shift_labels.view(-1)[ids])\n",
    "        \n",
    "        # Calculate Gradients \n",
    "        loss.backward()\n",
    "        \n",
    "        # Back Propogate\n",
    "        optimizer.step()\n",
    "        tr_loss+= loss.item()\n",
    "\n",
    "    # Loop through the next batch in the validation data loader\n",
    "    for batch,token_labels in val_dataloader:\n",
    "        CodeGPT.eval()\n",
    "        with torch.no_grad(): # Ensure gradients aren't updated\n",
    "            \n",
    "            # Seperate and format both the features and targets\n",
    "            token_labels = token_labels.to(device)\n",
    "            attn_mask = torch.tensor(token_labels.clone().detach() != 0, dtype=torch.uint8)\n",
    "            loss_mask = torch.tensor(token_labels.clone().detach() == 2, dtype=torch.uint8)\n",
    "            attn_mask = attn_mask.to(device)\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            # Calculate outputs based on the newly updated model\n",
    "            out = CodeGPT(batch,attention_mask=attn_mask)\n",
    "            \n",
    "            # Format output before calculating loss\n",
    "            logits = out.logits\n",
    "            labels = batch\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            flatten_shift_loss_mask = loss_mask[..., :-1].contiguous().view(-1)\n",
    "            ids = torch.nonzero(flatten_shift_loss_mask).view(-1)\n",
    "            \n",
    "            # Calculte Loss\n",
    "            loss = criterion(shift_logits.view(-1, shift_logits.size(-1))[ids], shift_labels.view(-1)[ids])\n",
    "            eval_loss += loss.item()\n",
    "            #print(eval_loss)\n",
    "\n",
    "    # Calculate the average Loss over the batch for both training and validation\n",
    "    tr_loss = tr_loss/len(train_dataloader)\n",
    "    eval_loss = eval_loss/len(val_dataloader)\n",
    "    train_loss_graph.append(tr_loss)\n",
    "    val_loss_graph.append(eval_loss)\n",
    "    print(\"Epoch: {} Train Loss: {} Val Loss: {}\".format(i+1,tr_loss,eval_loss))\n",
    "    torch.save(CodeGPT.state_dict(),'CodeGPT-{}-{}.pkl'.format(language, i+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f2c78-3359-4b90-89f1-cce4df0e1cfe",
   "metadata": {},
   "source": [
    "### Plot Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d0358-9e10-4c44-96c5-bda7b74f9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_graph,'k')\n",
    "plt.plot(val_loss_graph,'y')\n",
    "plt.legend([\"Training Loss\",\"Validation Loss\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch\")\n",
    "plt.savefig(\"CodeGPT-{}-Loss-graph.png\".format(language.upper()))\n",
    "\n",
    "losses = pd.DataFrame({'Tr_Loss': train_loss_graph, 'Val_Loss': val_loss_graph})\n",
    "\n",
    "losses.to_csv('Training_loss_{}_GPT.csv'.format(language.upper()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
